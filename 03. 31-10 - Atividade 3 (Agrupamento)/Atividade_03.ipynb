{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Agrupamento - Mineração de Dados**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nome: Davi Augusto Neves Leite**\n",
    "\n",
    "**Data de Entrega: 31/10/2023**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Materiais**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os principais recursos para a execução desta atividade podem ser vistos a seguir.\n",
    "\n",
    "1. **Software**\n",
    "\n",
    "- Sistemas Operacionais: Windows 11 para _desktop_;\n",
    "- Ambiente de Desenvolvimento Integrado: Microsoft Visual Studio Code;\n",
    "- Linguagem de Programação: Python 3.12.0 64-bit.\n",
    "\n",
    "2. **Hardware**\n",
    "\n",
    "- Notebook pessoal Lenovo Ideapad 330-15IKB com: processador Intel Core i7-8550U, HDD WD Blue WD10SPZX de 1TB, SSD Crucial BX500 de 1TB, 12 GB DDR4 de Memória RAM e placa de vídeo NVIDIA GeForce MX150 (2 GB GDDR5 de memória).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Instalação das Bibliotecas Principais**\n",
    "\n",
    "Nota: ao decorrer deste Notebook, outras bibliotecas podem ser utilizadas em quaisquer respectiva seção/conjunto de dados, dependendo da necessidade. Abaixo, há a instalação das principais que são comuns e utilizadas em todas ou quase todas seções/conjunto de dados.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install numpy\n",
    "%pip install pandas\n",
    "%pip install matplotlib\n",
    "%pip install seaborn\n",
    "%pip install plotly\n",
    "%pip install scikit-learn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Importação das Bibliotecas Principais**\n",
    "\n",
    "Nota: ao decorrer deste Notebook, outras bibliotecas podem ser utilizadas em quaisquer respectiva seção/conjunto de dados, dependendo da necessidade. Abaixo, há a importação das principais que são comuns e utilizadas em todas ou quase todas seções/conjunto de dados.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  # Manipulação de listas\n",
    "import pandas as pd  # Manipulação de tabelas\n",
    "import seaborn as sbn  # Geração de gráficos estatísticos\n",
    "import plotly.express as px  # Outro para geração de gráficos\n",
    "import matplotlib.pyplot as plt  # Geração de gráficos de listas\n",
    "import sklearn as skl  # Biblioteca para pré-processamento\n",
    "from copy import copy as cp  # Possibilitar copiar os objetos\n",
    "\n",
    "# Ignorar os avisos não importantes durante a execução deste notebook\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Conjunto de Dados: _Fashion MNIST_**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Descrição do Dataset:** este conjunto é composto por **70 mil imagens** a respeito de **10 peças de roupas distintas**. Cada imagem possui a **resolução de 28x28 (784 pixels) em escala de cinza e 256 níveis de cinza**. Desse total, exitem **7000 imagens** para cada uma das peças de roupas, ou classes.\n",
    "\n",
    "Cada classe pode ser vista a seguir.\n",
    "\n",
    "1. Camiseta\n",
    "2. Calça\n",
    "3. Pulôver\n",
    "4. Vestido\n",
    "5. Casaco\n",
    "6. Sandália\n",
    "7. Camisa\n",
    "8. Tênis\n",
    "9. Bolsa\n",
    "10. Bota de Tornozelo\n",
    "\n",
    "Este conjunto de dados pode ser acessado por meio de: [Fashion MNIST](https://www.openml.org/search?type=data&status=active&id=40996)\n",
    "(última data de acesso: 18 de out. de 2023).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Para fins práticos, apenas as classes _Camiseta_, _Vestido_, _Casaco_ e _Camisa_ serão utilizadas para esta atividade, tendo em vista que, por se tratar de uma base de dados de imagens, o processamento necessário para classificação é elevado.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Importação da Base de Dados**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para importar as imagens, utiliza-se o módulo **scikit-learn** capaz de carregar diversas bases de dados através do portal **OpenML**, o qual essa base de dados está disponível online.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importação da função necessária para importação de base de dados OpenML\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "# Carrega as imagens e suas classes separadamente\n",
    "images, targets = fetch_openml(\n",
    "    \"Fashion-MNIST\", return_X_y=True, as_frame=True, parser=\"auto\"\n",
    ")\n",
    "\n",
    "# Conversão das imagens para NumPy\n",
    "images = images.to_numpy()\n",
    "targets = targets.to_numpy().astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Pré-Processamento dos Dados**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \\* Separação das Classes de Interesse\n",
    "\n",
    "Inicia-se com a separação das classes de interesse, isto é: _Camiseta_, _Vestido_, _Casaco_ e _Camisa_. Cada qual será referida, respectivamente, pela identificação de 0 a 3 (_0 - Camiseta_, _1 - Vestido_, ...).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definição das classes de interesse\n",
    "labels_class = {0: 0, 3: 1, 4: 2, 6: 3}\n",
    "\n",
    "# Variáveis de seleção das imagens e classes respectivas\n",
    "selected_images = []\n",
    "selected_targets = []\n",
    "\n",
    "# Criação de um dicionário com os rótulos das classes para fácil acesso\n",
    "labels_desc = {0: \"camiseta\", 1: \"vestido\", 2: \"casaco\", 3: \"camisa\"}\n",
    "labels_names = [\"Camiseta\", \"Vestido\", \"Casaco\", \"Camisa\"]\n",
    "\n",
    "# Percorre as imagens da base de dados original\n",
    "for idx, label in enumerate(targets):\n",
    "    # Para cada rótulo de interesse, salvar as imagens e os rótulos\n",
    "    if label in labels_class.keys():\n",
    "        selected_images.append(images[idx])\n",
    "        selected_targets.append(labels_class[targets[idx]])\n",
    "\n",
    "# Conversão para NumPy\n",
    "selected_images = np.array(selected_images)\n",
    "selected_targets = np.array(selected_targets)\n",
    "\n",
    "print(\"Imagens Selecionadas:\\n\", selected_images)\n",
    "print(\"\\nRótulos Selecionados: \", selected_targets)\n",
    "print(\"\\nTotal de Dados: \", selected_images.shape[0])\n",
    "print(\"\\nCaracterísticas Totais: \", selected_images.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exibição das Classes de Interesse\n",
    "\n",
    "Abaixo, é possível visualizar uma amostra de cada classe, por meio do **matplotlib**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecionando um índice de cada classe\n",
    "idx_0 = np.where(selected_targets == 0)[0][0]\n",
    "idx_1 = np.where(selected_targets == 1)[0][0]\n",
    "idx_2 = np.where(selected_targets == 2)[0][0]\n",
    "idx_3 = np.where(selected_targets == 3)[0][0]\n",
    "idx_example_images = np.array([idx_0, idx_1, idx_2, idx_3])\n",
    "\n",
    "# Definindo o tamanho da figura\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Definindo o número de linhas e colunas das subfiguras\n",
    "fig_n_rows = 1\n",
    "fig_n_cols = 5\n",
    "\n",
    "# Mostrando as amostras de cada classe\n",
    "for label, image_idx in enumerate(labels_desc.keys()):\n",
    "    plt.subplot(fig_n_rows, fig_n_cols, label + 1)\n",
    "    plt.title(f'Classe \"{labels_desc[label]}\"')\n",
    "    plt.imshow(\n",
    "        selected_images[idx_example_images[image_idx]].reshape(28, 28), cmap=\"gray\"\n",
    "    )\n",
    "    plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tratamento de Dados Perdidos ou Inexistentes (NaN)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para verificar se algum dado está faltando, **caso não seja indicado pela descrição do _dataset_**, pode ser realizado a seguinte operação de força-bruta:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando o número de dados faltantes a partir do NumPy\n",
    "missing_selected_image = np.isnan(selected_images)\n",
    "missing_selected_image = np.sum(missing_selected_image)\n",
    "print(\"Número de Dados Perdidos: {0}\".format(missing_selected_image))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como é possível ver, não há nenhum dado perdido neste _dataset_ e, desta forma, não é necessário realizar nenhum método de tratamento neste contexto.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalização dos Dados\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para normalizar os dados via _Standardization (Z-Score)_ deste **dataset**, basta aplicar as seguintes operações:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função responsável pela normalização via Z-Score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Mostrando os dados não normalizados\n",
    "print(\"Dados Não Normalizados\")\n",
    "print(\n",
    "    \"\\tMédia: {0} | Desvio-Padrão: {1}\".format(\n",
    "        np.mean(selected_images), np.std(selected_images)\n",
    "    )\n",
    ")\n",
    "print(selected_images)\n",
    "\n",
    "\n",
    "# Aplicando a Normalização com Z-Score\n",
    "selected_images = StandardScaler().fit_transform(selected_images)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Mostrando os dados normalizados\n",
    "print(\"Dados Normalizados com Z-Score\")\n",
    "print(\n",
    "    \"\\tMédia: {0} | Desvio-Padrão: {1}\".format(\n",
    "        np.mean(selected_images), np.std(selected_images)\n",
    "    )\n",
    ")\n",
    "print(selected_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \\* Redução de Dimensionalidade: _Principal Component Analysis_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para reduzir a dimensionalidade deste **dataset**, é recomendado o uso do _Principal Component Analysis_ (PCA). Desta forma:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importação da função do PCA do sklearn\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Definindo o número de componentes do PCA\n",
    "n_components = 0.9\n",
    "\n",
    "# Aplicando o PCA\n",
    "pca = PCA(n_components=n_components, copy=True, whiten=False)\n",
    "projected_data = pca.fit_transform(selected_images)\n",
    "\n",
    "# Mostrando os dados projetados com PCA\n",
    "print(\"Dados Projetados com PCA\")\n",
    "print(projected_data)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Segundo: mostrando a matriz de covariância do PCA\n",
    "print(\"Variâncias\")\n",
    "print(pca.explained_variance_ratio_)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Transformando o conjunto de dados em DataFrame para melhor manipulação\n",
    "column_name = [\"pixel\" + str(i) for i in range(1, 785)]\n",
    "selected_images_zscore_frame = pd.DataFrame(selected_images, columns=column_name)\n",
    "\n",
    "# Terceiro: mostrando os componentes do PCA\n",
    "component_names = [\"component {}\".format(i) for i in range(len(pca.components_))]\n",
    "components_pca = pd.DataFrame(\n",
    "    data=pca.components_,\n",
    "    index=component_names,\n",
    "    columns=selected_images_zscore_frame.columns,\n",
    ")\n",
    "components_pca.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É possível, por exemplo, visualizar a variação do PCA na medida em que se aumentam as características (ou dimensões). A chamada **variância explicada** exprime exatamente a ideia de quanta variabilidade é possível capturar do conjunto de dados, sendo possível, a partir desta análise, levar a um melhor desempenho de treinamento do modelo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as px_go\n",
    "\n",
    "# Gráfico da variância do PCA, a partir dos componentes\n",
    "# exp_var_cum = np.cumsum(pca.explained_variance_ratio_)\n",
    "exp_var_cum = np.cumsum(np.round(pca.explained_variance_ratio_, decimals=3) * 100)\n",
    "\n",
    "fig_pca = px_go.Figure(\n",
    "    data=px_go.Scatter(x=list(range(1, len(exp_var_cum) + 1)), y=exp_var_cum)\n",
    ")\n",
    "fig_pca.update_layout(\n",
    "    title=\"Variância Explicada do PCA\",\n",
    "    xaxis_title=\"# de Características\",\n",
    "    yaxis_title=\"% Variância Explicada\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Agrupamento**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Texto\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subtítulo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Texto\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "orig_nbformat": 4,
  "polyglot_notebook": {
   "kernelInfo": {
    "defaultKernelName": "csharp",
    "items": [
     {
      "aliases": [],
      "name": "csharp"
     }
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
