{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classificação - Mineração de Dados**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nome: Davi Augusto Neves Leite**\n",
    "\n",
    "**Data de Entrega: 10/10/2023**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Materiais**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os principais recursos para a execução desta atividade podem ser vistos a seguir.\n",
    "\n",
    "1. **Software**\n",
    "\n",
    "- Sistemas Operacionais: Windows 11 para _desktop_;\n",
    "- Ambiente de Desenvolvimento Integrado: Microsoft Visual Studio Code;\n",
    "- Linguagem de Programação: Python 3.12.0 64-bit.\n",
    "\n",
    "2. **Hardware**\n",
    "\n",
    "- Notebook pessoal Lenovo Ideapad 330-15IKB com: processador Intel Core i7-8550U, HDD WD Blue WD10SPZX de 1TB, SSD Crucial BX500 de 1TB, 12 GB DDR4 de Memória RAM e placa de vídeo NVIDIA GeForce MX150 (2 GB GDDR5 de memória).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Instalação das Bibliotecas Principais**\n",
    "\n",
    "Nota: ao decorrer deste Notebook, outras bibliotecas podem ser utilizadas em quaisquer respectiva seção/conjunto de dados, dependendo da necessidade. Abaixo, há a instalação das principais que são comuns e utilizadas em todas ou quase todas seções/conjunto de dados.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install numpy\n",
    "%pip install pandas\n",
    "%pip install matplotlib\n",
    "%pip install seaborn\n",
    "%pip install plotly\n",
    "%pip install scikit-learn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Importação das Bibliotecas Principais**\n",
    "\n",
    "Nota: ao decorrer deste Notebook, outras bibliotecas podem ser utilizadas em quaisquer respectiva seção/conjunto de dados, dependendo da necessidade. Abaixo, há a importação das principais que são comuns e utilizadas em todas ou quase todas seções/conjunto de dados.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  # Manipulação de listas\n",
    "import pandas as pd  # Manipulação de tabelas\n",
    "import seaborn as sbn  # Geração de gráficos estatísticos\n",
    "import plotly.express as px  # Outro para geração de gráficos\n",
    "import matplotlib.pyplot as plt  # Geração de gráficos de listas\n",
    "import sklearn as skl  # Biblioteca para pré-processamento\n",
    "from copy import copy as cp  # Possibilitar copiar os objetos\n",
    "\n",
    "# Ignorar os avisos não importantes durante a execução deste notebook\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Conjunto de Dados: _Fashion MNIST_**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Descrição do Dataset:** este conjunto é composto por **70 mil imagens** a respeito de **10 peças de roupas distintas**. Cada imagem possui a **resolução de 28x28 (784 pixels) em escala de cinza e 256 níveis de cinza**. Desse total, exitem **7000 imagens** para cada uma das peças de roupas, ou classes.\n",
    "\n",
    "Cada classe pode ser vista a seguir.\n",
    "\n",
    "1. Camiseta\n",
    "2. Calça\n",
    "3. Pulôver\n",
    "4. Vestido\n",
    "5. Casaco\n",
    "6. Sandália\n",
    "7. Camisa\n",
    "8. Tênis\n",
    "9. Bolsa\n",
    "10. Bota de Tornozelo\n",
    "\n",
    "Este conjunto de dados pode ser acessado por meio de: [Fashion MNIST](https://www.openml.org/search?type=data&status=active&id=40996)\n",
    "(última data de acesso: 02 de out. de 2023).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Para fins práticos, apenas as classes _camiseta_, _vestido_, _casaco_ e _camisa_ serão utilizadas para esta atividade, tendo em vista que, por se tratar de uma base de dados de imagens, o processamento necessário para classificação é elevado.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Importação da Base de Dados**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para importar as imagens, utiliza-se o módulo **scikit-learn** capaz de carregar diversas bases de dados através do portal **OpenML**, o qual essa base de dados está disponível online.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importação da função necessária para importação de base de dados OpenML\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "# Carrega as imagens e suas classes separadamente\n",
    "images, targets = fetch_openml(\n",
    "    \"Fashion-MNIST\", return_X_y=True, as_frame=True, parser=\"auto\"\n",
    ")\n",
    "\n",
    "# Conversão das imagens para NumPy\n",
    "images = images.to_numpy()\n",
    "targets = targets.to_numpy().astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Pré-Processamento dos Dados**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separação das Classes de Interesse\n",
    "\n",
    "Inicia-se com a separação das classes de interesse, isto é: _camiseta_, _vestido_, _casaco_ e _camisa_. Cada qual será referida, respectivamente, pela identificação de 0 a 3 (_0 - camiseta_, _1 - vestido_, ...).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definição das classes de interesse\n",
    "labels_class = {0: 0, 3: 1, 4: 2, 6: 3}\n",
    "\n",
    "# Variáveis de seleção das imagens e classes respectivas\n",
    "selected_images = []\n",
    "selected_targets = []\n",
    "\n",
    "# Criação de um dicionário com os rótulos das classes para fácil acesso\n",
    "labels_desc = {0: \"camiseta\", 1: \"vestido\", 2: \"casaco\", 3: \"camisa\"}\n",
    "labels_names = [\"Camiseta\", \"Vestido\", \"Casaco\", \"Camisa\"]\n",
    "\n",
    "# Percorre as imagens da base de dados original\n",
    "for idx, label in enumerate(targets):\n",
    "    # Para cada rótulo de interesse, salvar as imagens e os rótulos\n",
    "    if label in labels_class.keys():\n",
    "        selected_images.append(images[idx])\n",
    "        selected_targets.append(labels_class[targets[idx]])\n",
    "\n",
    "# Conversão para NumPy\n",
    "selected_images = np.array(selected_images)\n",
    "selected_targets = np.array(selected_targets)\n",
    "\n",
    "print(\"Imagens Selecionadas:\\n\", selected_images)\n",
    "print(\"\\nRótulos Selecionados: \", selected_targets)\n",
    "print(\"\\nTotal de Dados: \", selected_images.shape[0])\n",
    "print(\"\\nCaracterísticas Totais: \", selected_images.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exibição das Classes de Interesse\n",
    "\n",
    "Abaixo, é possível visualizar uma amostra de cada classe, por meio do **matplotlib**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecionando um índice de cada classe\n",
    "idx_0 = np.where(selected_targets == 0)[0][0]\n",
    "idx_1 = np.where(selected_targets == 1)[0][0]\n",
    "idx_2 = np.where(selected_targets == 2)[0][0]\n",
    "idx_3 = np.where(selected_targets == 3)[0][0]\n",
    "idx_example_images = np.array([idx_0, idx_1, idx_2, idx_3])\n",
    "\n",
    "# Definindo o tamanho da figura\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Definindo o número de linhas e colunas das subfiguras\n",
    "fig_n_rows = 1\n",
    "fig_n_cols = 5\n",
    "\n",
    "# Mostrando as amostras de cada classe\n",
    "for label, image_idx in enumerate(labels_desc.keys()):\n",
    "    plt.subplot(fig_n_rows, fig_n_cols, label + 1)\n",
    "    plt.title(f'Classe \"{labels_desc[label]}\"')\n",
    "    plt.imshow(\n",
    "        selected_images[idx_example_images[image_idx]].reshape(28, 28), cmap=\"gray\"\n",
    "    )\n",
    "    plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tratamento de Dados Perdidos ou Inexistentes (NaN)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para verificar se algum dado está faltando, **caso não seja indicado pela descrição do _dataset_**, pode ser realizado a seguinte operação de força-bruta:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando o número de dados faltantes a partir do NumPy\n",
    "missing_selected_image = np.isnan(selected_images)\n",
    "missing_selected_image = np.sum(missing_selected_image)\n",
    "print(\"Número de Dados Perdidos: {0}\".format(missing_selected_image))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como é possível ver, não há nenhum dado perdido neste _dataset_ e, desta forma, não é necessário realizar nenhum método de tratamento neste contexto.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalização dos Dados\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para normalizar os dados via _Standardization (Z-Score)_ deste **dataset**, basta aplicar as seguintes operações:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função responsável pela normalização via Z-Score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Mostrando os dados não normalizados\n",
    "print(\"Dados Não Normalizados\")\n",
    "print(\n",
    "    \"\\tMédia: {0} | Desvio-Padrão: {1}\".format(\n",
    "        np.mean(selected_images), np.std(selected_images)\n",
    "    )\n",
    ")\n",
    "print(selected_images)\n",
    "\n",
    "\n",
    "# Aplicando a Normalização com Z-Score\n",
    "selected_images = StandardScaler().fit_transform(selected_images)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Mostrando os dados normalizados\n",
    "print(\"Dados Normalizados com Z-Score\")\n",
    "print(\n",
    "    \"\\tMédia: {0} | Desvio-Padrão: {1}\".format(\n",
    "        np.mean(selected_images), np.std(selected_images)\n",
    "    )\n",
    ")\n",
    "print(selected_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Redução de Dimensionalidade: _Principal Component Analysis_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para reduzir a dimensionalidade deste **dataset**, é recomendado o uso do _Principal Component Analysis_ (PCA). Desta forma:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importação da função do PCA do sklearn\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Definindo o número de componentes do PCA\n",
    "n_components = 0.9\n",
    "\n",
    "# Aplicando o PCA\n",
    "pca = PCA(n_components=n_components, copy=True, whiten=False)\n",
    "projected_data = pca.fit_transform(selected_images)\n",
    "\n",
    "# Mostrando os dados projetados com PCA\n",
    "print(\"Dados Projetados com PCA\")\n",
    "print(projected_data)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Segundo: mostrando a matriz de covariância do PCA\n",
    "print(\"Variâncias\")\n",
    "print(pca.explained_variance_ratio_)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Transformando o conjunto de dados em DataFrame para melhor manipulação\n",
    "column_name = [\"pixel\" + str(i) for i in range(1, 785)]\n",
    "selected_images_zscore_frame = pd.DataFrame(selected_images, columns=column_name)\n",
    "\n",
    "# Terceiro: mostrando os componentes do PCA\n",
    "component_names = [\"component {}\".format(i) for i in range(len(pca.components_))]\n",
    "components_pca = pd.DataFrame(\n",
    "    data=pca.components_,\n",
    "    index=component_names,\n",
    "    columns=selected_images_zscore_frame.columns,\n",
    ")\n",
    "components_pca.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É possível, por exemplo, visualizar a variação do PCA na medida em que se aumentam as características (ou dimensões). A chamada **variância explicada** exprime exatamente a ideia de quanta variabilidade é possível capturar do conjunto de dados, sendo possível, a partir desta análise, levar a um melhor desempenho de treinamento do modelo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as px_go\n",
    "\n",
    "# Gráfico da variância do PCA, a partir dos componentes\n",
    "# exp_var_cum = np.cumsum(pca.explained_variance_ratio_)\n",
    "exp_var_cum = np.cumsum(np.round(pca.explained_variance_ratio_, decimals=3) * 100)\n",
    "\n",
    "fig_pca = px_go.Figure(\n",
    "    data=px_go.Scatter(x=list(range(1, len(exp_var_cum) + 1)), y=exp_var_cum)\n",
    ")\n",
    "fig_pca.update_layout(\n",
    "    title=\"Variância Explicada do PCA\",\n",
    "    xaxis_title=\"# de Características\",\n",
    "    yaxis_title=\"% Variância Explicada\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Classificação**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma das características dos _datasets MNIST_ é de terem pixels bem diferenciados entre si e, portanto, é possível aplicar os classificadores sem a necessidade de uma extração prévia de características, como por meio das técnicas de extração de texturas como os **Descritores de Haralick** ou do **_Local Binary Pattern_**.\n",
    "\n",
    "Para validar os dados, será utilizado a técnica de **_cross-validation_**. Nesta técnica, os dados são separados entre um conjunto de treinamento e um de teste. O de treinamento, como o nome sugere, serve para o classificador realizar predições e \"aprender\" as diferentes classes. Já o de teste é utilizado para verificar o quanto o classificador \"pode aprender\" com o treinamento, ou seja, são feitas predições das classes neste conjunto.\n",
    "\n",
    "Para isso, é realizado a separação de 80% do conjunto total para treinamento e 20% para conjunto de teste.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para separação dos conjuntos\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Divisão dos conjuntos de treinamento e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    selected_images, selected_targets, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(\"Conjunto de Treinamento\\n\", X_train)\n",
    "print(\"Rótulos de Treinamento\\n\", y_train)\n",
    "print(\"Quantidade de Dados de Treinamento: \", X_train.shape[0])\n",
    "print()\n",
    "print(\"Conjunto de Teste\\n\", X_test)\n",
    "print(\"Rótulos de Teste\\n\", y_test)\n",
    "print(\"Quantidade de Dados de Teste: \", X_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Decision Trees_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As Árvores de Decisão são modelos de aprendizado de máquina supervisionado que representam decisões e suas consequências diretas, em forma de árvore. Neste modelo, cada nó interno representa um teste em um atributo, cada ramo representa um resultado do teste e cada nó folha representa uma classe. Por conta disso, as Árvores de Decisão são altamente interpretáveis, capazes de lidar com dados categóricos e numéricos, ainda que possam ser propensas ao _overfitting_ se não ajustadas corretamente.\n",
    "\n",
    "Desta forma, para aplicar a Árvore de Decisão para o _dataset_ proposto basta realizar as seguintes etapas a seguir.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Métricas para análise de desempenho\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    ConfusionMatrixDisplay,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    ")\n",
    "\n",
    "# Árvore de Decisão para Classificação\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Definindo hiperparâmetros\n",
    "max_depth = 100\n",
    "\n",
    "# Criando a estrutura básica\n",
    "dec_tree = DecisionTreeClassifier(max_depth=max_depth, random_state=42)\n",
    "\n",
    "# Realizando o treinamento\n",
    "dec_tree.fit(X=X_train, y=y_train)\n",
    "\n",
    "# Realizando a predição no conjunto de teste\n",
    "y_pred = dec_tree.predict(X=X_test)\n",
    "\n",
    "# Mostrando a acurácia obtida\n",
    "dec_tree_accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Acurácia: {dec_tree_accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como é possível visualizar, a Árvore de Decisão com **100 nós de profundidade máxima** conseguiu obter **76% de acurácia para classificação do conjunto de teste**. Além da acurácia, é possível visualizar o relatório completo abaixo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrando o relatório completo de classificação\n",
    "print(\"\\nRelatório de Classificação:\")\n",
    "print(classification_report(y_test, y_pred, target_names=labels_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outra importante métrica é a matriz de confusão. Essa métrica nada mais é do que uma tabela que compara as previsões do modelo com os valores reais dos dados. Nela, são mostrados quantos exemplos de cada classe foram classificados corretamente (verdadeiros positivos e verdadeiros negativos) e quantos foram classificados de forma incorreta (falsos positivos e falsos negativos).\n",
    "\n",
    "A seguir, é possível visualizar a matriz de confusão e o respectivo mapa de calor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando e mostrando a matriz de confusão com relação ao conj. de teste\n",
    "print(\"Matriz de Confusão:\\n\")\n",
    "print(confusion_matrix(y_test, y_pred, labels=dec_tree.classes_))\n",
    "dec_tree_cm_disp = ConfusionMatrixDisplay.from_predictions(\n",
    "    y_test, y_pred, display_labels=labels_names, cmap=\"Blues\"\n",
    ").figure_.suptitle(\"Matriz de Confusão\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Bagging_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O _Bagging_ consiste em uma técnica de _ensemble learning_ em que visa melhorar a precisão e reduzir a ocorrência de _overfitting_ de determinado modelo. Para tanto, nesta técnica são construídos vários modelos independentes, utilizando subconjuntos aleatórios do conjunto original (com reposição) e, após isso, é agregado suas previsões para a tomada de decisão final. Em outras palavras e tomando como exemplo a Árvore de Decisão, seriam aplicados várias Árvores de Decisão independente para subconjuntos do conjunto de treinamento e, a partir do resultado final, haveria a combinação de todos os modelos. No caso da classificação, a classe mais frequente entre as previsões obtidas das Árvores de Decisão seria a escolhida no final do processo.\n",
    "\n",
    "Desta forma, para aplicar o _Bagging com Árvore de Decisão_ para o _dataset_ proposto basta realizar as seguintes etapas a seguir.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Métricas para análise de desempenho\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    ConfusionMatrixDisplay,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    ")\n",
    "\n",
    "# Bagging para Classificação juntamente com a Árvore de Decisão\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Definindo hiperparâmetros do Bagging\n",
    "max_samples = 0.6\n",
    "max_features = 0.6\n",
    "\n",
    "# Definindo hiperparâmetros da Árvore de Decisão\n",
    "max_depth = 100\n",
    "\n",
    "# Criando a estrutura básica\n",
    "bagging = BaggingClassifier(\n",
    "    estimator=DecisionTreeClassifier(max_depth=max_depth, random_state=42),\n",
    "    max_samples=max_samples,\n",
    "    max_features=max_features,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "# Realizando o treinamento\n",
    "bagging.fit(X=X_train, y=y_train)\n",
    "\n",
    "# Realizando a predição no conjunto de teste\n",
    "y_pred = bagging.predict(X=X_test)\n",
    "\n",
    "# Mostrando a acurácia obtida\n",
    "bagging_accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Acurácia: {bagging_accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como é possível visualizar, o _Bagging com Árvore de Decisão_, utilizando **60% de amostras máximas** e **60% de características máximas**, conseguiu obter **82% de acurácia para classificação do conjunto de teste**. Além da acurácia, é possível visualizar o relatório completo abaixo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrando o relatório completo de classificação\n",
    "print(\"\\nRelatório de Classificação:\")\n",
    "print(classification_report(y_test, y_pred, target_names=labels_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A seguir, é possível visualizar a matriz de confusão e o respectivo mapa de calor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando e mostrando a matriz de confusão com relação ao conj. de teste\n",
    "print(\"Matriz de Confusão:\\n\")\n",
    "print(confusion_matrix(y_test, y_pred, labels=bagging.classes_))\n",
    "bagging_cm_disp = ConfusionMatrixDisplay.from_predictions(\n",
    "    y_test, y_pred, display_labels=labels_names, cmap=\"Blues\"\n",
    ").figure_.suptitle(\"Matriz de Confusão\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _AdaBoost_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diferentemente do _Bagging_, o _Boosting_ é uma técnica de _ensemble learning_ que combina múltiplos modelos fracos para a criação de um modelo forte. Neste caso, os modelos são treinados sequencialmente e, desta forma, cada modelo tenta corrigir os erros do modelo anterior. A ideia é de que as classes \"mal classificadas\" recebam um peso maior a cada iteração e modelo. O _Adaptative Boosting_, ou _AdaBoost_, é um algoritmo de _Boosting_ que é particularmente eficaz em problemas de classificação binária, se destacando nas classes de \"difícil previsão\" de modelos normais.\n",
    "\n",
    "Desta forma, para aplicar o _AdaBoost com Árvore de Decisão_ para o _dataset_ proposto basta realizar as seguintes etapas a seguir.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Métricas para análise de desempenho\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    ConfusionMatrixDisplay,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    ")\n",
    "\n",
    "# AdaBoost para Classificação, com Árvore de Decisão\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Definindo hiperparâmetros do AdaBoost\n",
    "n_estimators = 100\n",
    "\n",
    "# Definindo hiperparâmetros da Árvore de Decisão\n",
    "max_depth = 100\n",
    "\n",
    "# Criando a estrutura básica\n",
    "ada_boost = AdaBoostClassifier(\n",
    "    estimator=DecisionTreeClassifier(max_depth=max_depth, random_state=42),\n",
    "    n_estimators=n_estimators,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "# Realizando o treinamento\n",
    "ada_boost.fit(X=X_train, y=y_train)\n",
    "\n",
    "# Realizando a predição no conjunto de teste\n",
    "y_pred = ada_boost.predict(X=X_test)\n",
    "\n",
    "# Mostrando a acurácia obtida\n",
    "ada_boost_accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Acurácia: {ada_boost_accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como é possível visualizar, o _AdaBoost com Árvore de Decisão_ utilizando **100 estimadores** conseguiu obter **77% de acurácia para classificação do conjunto de teste**. Além da acurácia, é possível visualizar o relatório completo abaixo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrando o relatório completo de classificação\n",
    "print(\"\\nRelatório de Classificação:\")\n",
    "print(classification_report(y_test, y_pred, target_names=labels_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A seguir, é possível visualizar a matriz de confusão e o respectivo mapa de calor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando e mostrando a matriz de confusão com relação ao conj. de teste\n",
    "print(\"Matriz de Confusão:\\n\")\n",
    "print(confusion_matrix(y_test, y_pred, labels=ada_boost.classes_))\n",
    "ada_boost_cm_disp = ConfusionMatrixDisplay.from_predictions(\n",
    "    y_test, y_pred, display_labels=labels_names, cmap=\"Blues\"\n",
    ").figure_.suptitle(\"Matriz de Confusão\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Random Forest_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O _Random Forest_ é um algoritmo de _ensemble learning_ que combina **múltiplas Árvores de Decisão** para melhorar a tomada de decisões. Nesta técnica, cada Árvore de Decisão é treinada em diferentes subconjuntos do conjunto de dados original. A principal diferença desta para com o uso de _Bagging com Árvore de Decisão_ está em que o _Random Forest_, durante o treinamento, seleciona aleatoriamente os subconjuntos de dados para cada divisão de nó. Em outras palavras, enquanto que no _Bagging_ para cada divisão em um nó da árvore **todos** os atributos são considerados, no _Random Forest_ para cada divisão de nó é levado em consideração diferentes conjuntos de atributos. Por conta disso, o _Random Forest_ reduz ainda mais a correlação entre as Árvores de Decisão, geralmente levando a modelos mais robustos e precisos.\n",
    "\n",
    "Desta forma, para aplicar o _Random Forest_ para o _dataset_ proposto basta realizar as seguintes etapas a seguir.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Métricas para análise de desempenho\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    ConfusionMatrixDisplay,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    ")\n",
    "\n",
    "# Random Forest para Classificação\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Definindo hiperparâmetros do Random Forest\n",
    "n_estimators = 100\n",
    "max_depth = 100\n",
    "\n",
    "# Criando a estrutura básica\n",
    "rand_forest = RandomForestClassifier(\n",
    "    n_estimators=n_estimators, max_depth=max_depth, random_state=42\n",
    ")\n",
    "\n",
    "# Realizando o treinamento\n",
    "rand_forest.fit(X=X_train, y=y_train)\n",
    "\n",
    "# Realizando a predição no conjunto de teste\n",
    "y_pred = rand_forest.predict(X=X_test)\n",
    "\n",
    "# Mostrando a acurácia obtida\n",
    "rand_forest_accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Acurácia: {rand_forest_accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como é possível visualizar, o _Random Forest_ com **100 estimadores e 100 de profundidade máxima** conseguiu obter **85% de acurácia para classificação do conjunto de teste**. Além da acurácia, é possível visualizar o relatório completo abaixo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrando o relatório completo de classificação\n",
    "print(\"\\nRelatório de Classificação:\")\n",
    "print(classification_report(y_test, y_pred, target_names=labels_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A seguir, é possível visualizar a matriz de confusão e o respectivo mapa de calor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando e mostrando a matriz de confusão com relação ao conj. de teste\n",
    "print(\"Matriz de Confusão:\\n\")\n",
    "print(confusion_matrix(y_test, y_pred, labels=rand_forest.classes_))\n",
    "rand_forest_cm_disp = ConfusionMatrixDisplay.from_predictions(\n",
    "    y_test, y_pred, display_labels=labels_names, cmap=\"Blues\"\n",
    ").figure_.suptitle(\"Matriz de Confusão\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ajuste de Hiperparâmetros do Melhor Modelo: **_Random Forest_**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando o gráfico de comparativo de acurácia entre modelos\n",
    "acc_names_fig = np.array(\n",
    "    [\"Decision Tree (DT)\", \"Bagging (with DT)\", \"AdaBoost (with DT)\", \"Random Forest\"]\n",
    ")\n",
    "acc_values_fig = np.array(\n",
    "    [\n",
    "        dec_tree_accuracy * 100,\n",
    "        bagging_accuracy * 100,\n",
    "        ada_boost_accuracy * 100,\n",
    "        rand_forest_accuracy * 100,\n",
    "    ]\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(acc_names_fig, acc_values_fig)\n",
    "plt.suptitle(\"Acurácia dos Modelos para Fashion-MNIST*\")\n",
    "plt.title(\"*: apenas quatro classes\")\n",
    "plt.xlabel(\"Modelos\")\n",
    "plt.ylabel(\"Acurácia Obtida (em %)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tendo em vista os resultados de **acurácia** obtidos por cada modelo executado anteriormente, e os quais são possíveis de visualizar no gráfico anterior, obteve-se que o melhor modelo foi o **Random Forest** com **85% de acurácia**. Desta forma, torna-se necessário verificar se é possível melhorar os hiperparâmetros para a obtenção de melhores resultados.\n",
    "\n",
    "Para tanto, é possível aplicar a técnica de **_Grid Search_**, a qual consiste em realizar testes exaustivos com base em um conjunto de valores especificados para os hiperparâmetros. Em outras palavras, esta técnica testa todas as combinações de hiperparâmetros especificadas pelo usuário para um determinado modelo, obtendo a melhor combinação ao final dos testes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importação do Grid Search para melhorar o modelo\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Criação de um dicionário para conter um conjunto de valores de teste\n",
    "# Quatro números de estimadores máximo e quatro números de profundidade máxima\n",
    "param_grid = [\n",
    "    {\n",
    "        \"n_estimators\": [10, 50, 100, 1000],\n",
    "        \"max_depth\": [10, 50, 100, 1000],\n",
    "    }\n",
    "]\n",
    "\n",
    "# Aplicação do Grid Search: execução exaustiva!\n",
    "grid_search_rand_forest = GridSearchCV(\n",
    "    estimator=RandomForestClassifier(random_state=42), param_grid=param_grid\n",
    ")\n",
    "\n",
    "# Treinamento do Grid Search\n",
    "grid_search_rand_forest.fit(X=X_train, y=y_train)\n",
    "\n",
    "# Mostrando os melhores parâmetros obtidos\n",
    "print(f\"Melhores hiperparâmetros: {grid_search_rand_forest.best_params_}\")\n",
    "\n",
    "# Realizando a predição no conjunto de teste\n",
    "y_pred = grid_search_rand_forest.predict(X=X_test)\n",
    "\n",
    "# Mostrando a acurácia obtida\n",
    "grid_search_rand_forest_accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Acurácia: {grid_search_rand_forest_accuracy:.2f}\")\n",
    "\n",
    "# Mostrando o relatório completo de classificação\n",
    "print(\"\\nRelatório de Classificação:\")\n",
    "print(classification_report(y_test, y_pred, target_names=labels_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como é possível visualizar, o _Random Forest_ com **XX estimadores e XX de profundidade máxima** conseguiu obter **XX% de acurácia para classificação do conjunto de teste**. Também, é possível visualizar a matriz de confusão a seguir.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando e mostrando a matriz de confusão com relação ao conj. de teste\n",
    "print(\"Matriz de Confusão:\\n\")\n",
    "print(\n",
    "    confusion_matrix(y_test, y_pred, labels=grid_search_rand_forest_accuracy.classes_)\n",
    ")\n",
    "rand_forest_cm_disp = ConfusionMatrixDisplay.from_predictions(\n",
    "    y_test, y_pred, display_labels=labels_names, cmap=\"Blues\"\n",
    ").figure_.suptitle(\"Matriz de Confusão\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Multiclasse para Binário**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _One vs All (OVA) / One vs Rest (OVR)_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _One vs One (OVO)_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "orig_nbformat": 4,
  "polyglot_notebook": {
   "kernelInfo": {
    "defaultKernelName": "csharp",
    "items": [
     {
      "aliases": [],
      "name": "csharp"
     }
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
